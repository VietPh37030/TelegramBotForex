"""
News Crawler Module - Crawl vÃ  phÃ¢n tÃ­ch tin tá»©c forex
Sá»­ dá»¥ng Gemini Ä‘á»ƒ dá»‹ch vÃ  phÃ¢n tÃ­ch táº§m quan trá»ng
"""
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import re
from dataclasses import dataclass

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False


@dataclass
class NewsEvent:
    """Sá»± kiá»‡n tin tá»©c kinh táº¿"""
    time: str
    currency: str
    impact: str  # HIGH, MEDIUM, LOW
    event: str
    forecast: str
    previous: str
    actual: str
    title_vi: str  # TiÃªu Ä‘á» tiáº¿ng Viá»‡t


class NewsCrawler:
    """
    Crawl tin tá»©c kinh táº¿ tá»« ForexFactory, Investing.com
    Dá»‹ch sang tiáº¿ng Viá»‡t báº±ng AI
    """
    
    # More realistic browser headers to bypass bot detection
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
    }
    
    # Tin tá»©c áº£nh hÆ°á»Ÿng máº¡nh Ä‘áº¿n VÃ ng
    GOLD_IMPACT_EVENTS = [
        'Non-Farm', 'NFP', 'CPI', 'PPI', 'GDP', 'FOMC', 'Fed', 'Interest Rate',
        'Unemployment', 'Retail Sales', 'PMI', 'ISM', 'Core', 'Inflation',
        'Powell', 'Yellen', 'Treasury', 'Jobs', 'Employment'
    ]
    
    def __init__(self, gemini_api_key: str = None):
        self.session = requests.Session()
        self.session.headers.update(self.HEADERS)
        self.gemini_key = gemini_api_key
        self.model = None
        
        if GENAI_AVAILABLE and gemini_api_key:
            genai.configure(api_key=gemini_api_key)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
    
    def get_economic_calendar(self) -> List[NewsEvent]:
        """
        Láº¥y lá»‹ch kinh táº¿ hÃ´m nay
        Priority: NASDAQ API > CafeF (no more ForexFactory)
        """
        events = []
        
        # Try NASDAQ first (US Economic Calendar - reliable)
        try:
            events = self._crawl_nasdaq()
            if events:
                print(f"âœ… NASDAQ: {len(events)} events loaded")
                return events
        except Exception as e:
            pass  # Silent fail
        
        # Fallback to CafeF 
        try:
            events = self._crawl_cafef()
            if events:
                print(f"âœ… CafeF: {len(events)} events loaded")
                return events
        except Exception as e:
            pass  # Silent fail
        
        # Return empty if all fail
        return []
    
    def _crawl_nasdaq(self) -> List[NewsEvent]:
        """
        Láº¥y lá»‹ch kinh táº¿ tá»« NASDAQ API (Reliable, no rate limit)
        """
        url = "https://api.nasdaq.com/api/calendar/economicevents"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        
        today_str = datetime.now().strftime("%Y-%m-%d")
        params = {'date': today_str}
        
        response = self.session.get(url, headers=headers, params=params, timeout=10, verify=False)
        
        if response.status_code != 200:
            raise Exception(f"HTTP {response.status_code}")
        
        data = response.json()
        rows = data.get('data', {}).get('calendar', {}).get('rows', [])
        
        events = []
        
        # Dictionary to translate NASDAQ events to Vietnamese
        translate_dict = {
            "GDP": "GDP (Tá»•ng sáº£n pháº©m quá»‘c ná»™i)",
            "CPI": "CPI (Láº¡m phÃ¡t)",
            "PPI": "PPI (Chá»‰ sá»‘ sáº£n xuáº¥t)",
            "Nonfarm Payrolls": "Báº£ng lÆ°Æ¡ng Non-Farm",
            "Unemployment Rate": "Tá»· lá»‡ Tháº¥t nghiá»‡p",
            "Fed Interest Rate": "LÃ£i suáº¥t Fed",
            "FOMC": "BiÃªn báº£n há»p FOMC",
            "Initial Jobless Claims": "ÄÆ¡n xin trá»£ cáº¥p tháº¥t nghiá»‡p",
            "Retail Sales": "Doanh sá»‘ BÃ¡n láº»",
            "Crude Oil": "Dá»± trá»¯ Dáº§u thÃ´",
            "Consumer Confidence": "Niá»m tin TiÃªu dÃ¹ng"
        }
        
        for item in rows:
            # Only US events
            if item.get('country') != 'United States':
                continue
            
            name = item.get('eventTitle', '')
            time_str = item.get('time', '00:00')
            actual = item.get('actual', '')
            forecast = item.get('consensus', '')
            
            # Check if important
            is_important = any(key in name for key in translate_dict.keys())
            
            if is_important:
                # Translate to Vietnamese
                vn_name = name
                for en, vn in translate_dict.items():
                    if en in name:
                        vn_name = vn
                        break
                
                events.append(NewsEvent(
                    time=time_str,
                    currency='USD',
                    impact='HIGH',
                    event=name,
                    title_vi=vn_name,
                    forecast=forecast,
                    previous=actual
                ))
        
        return events
    
    def _crawl_cafef(self) -> List[NewsEvent]:
        """
        Láº¥y tin tá»©c tá»« CafeF (Vietnamese financial news)
        Fallback khi NASDAQ khÃ´ng cÃ³ data
        """
        from bs4 import BeautifulSoup
        
        url = "https://cafef.vn/tai-chinh-quoc-te.chn"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = self.session.get(url, headers=headers, timeout=10, verify=False)
        
        if response.status_code != 200:
            raise Exception(f"HTTP {response.status_code}")
        
        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('h3', limit=15)
        
        events = []
        keywords = ["VÃ ng", "USD", "Fed", "LÃ£i suáº¥t", "Láº¡m phÃ¡t", "Chá»©ng khoÃ¡n", "Gold"]
        
        current_time = datetime.now().strftime("%H:%M")
        
        for article in articles:
            text = article.text.strip()
            
            if any(k.lower() in text.lower() for k in keywords):
                events.append(NewsEvent(
                    time=current_time,
                    currency='USD',
                    impact='MEDIUM',
                    event=text[:100],  # Truncate to 100 chars
                    title_vi=text[:100],
                    forecast='',
                    previous=''
                ))
                
                if len(events) >= 5:  # Max 5 events
                    break
        
        return events
    
    def _crawl_forexfactory(self) -> List[NewsEvent]:
        """
        Láº¥y data tá»« ForexFactory JSON API (Hidden endpoint)
        URL tháº§n thÃ¡nh: https://nfs.faireconomy.media/ff_calendar_thisweek.json
        """
        url = "https://nfs.faireconomy.media/ff_calendar_thisweek.json"
        
        try:
            response = self.session.get(url, timeout=15)
            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}")
            
            data = response.json()
            events = []
            
            # Get today's date
            today = datetime.now().strftime("%Y-%m-%d")
            
            for item in data:
                try:
                    # Parse date
                    event_date = item.get('date', '')[:10]  # YYYY-MM-DD
                    
                    # Only get today and tomorrow's events
                    if event_date < today:
                        continue
                    
                    # Map impact
                    impact_map = {
                        'Holiday': 'LOW',
                        'Low': 'LOW',
                        'Medium': 'MEDIUM',
                        'High': 'HIGH'
                    }
                    impact = impact_map.get(item.get('impact', 'Low'), 'LOW')
                    
                    # Parse time
                    time_str = item.get('date', '')[11:16]  # HH:MM
                    if not time_str:
                        time_str = 'All Day'
                    
                    events.append(NewsEvent(
                        time=time_str,
                        currency=item.get('country', 'USD'),
                        impact=impact,
                        event=item.get('title', ''),
                        forecast=str(item.get('forecast', '')),
                        previous=str(item.get('previous', '')),
                        actual=str(item.get('actual', '')),
                        title_vi=''  # Sáº½ dá»‹ch sau náº¿u cáº§n
                    ))
                except:
                    continue
            
            print(f"âœ… ForexFactory JSON: {len(events)} events loaded")
            return events
            
        except Exception as e:
            print(f"âš ï¸ ForexFactory JSON failed: {e}")
            return []
    
    def _get_news_from_api(self) -> List[NewsEvent]:
        """Fallback API for economic calendar"""
        # Using mock data as fallback since most calendar APIs require auth
        return self._get_mock_calendar()
    
    def _crawl_investing_calendar(self) -> List[NewsEvent]:
        """Crawl tá»« Investing.com"""
        url = "https://www.investing.com/economic-calendar/"
        
        response = self.session.get(url, timeout=10)
        if response.status_code != 200:
            raise Exception(f"HTTP {response.status_code}")
        
        if not BS4_AVAILABLE:
            raise Exception("BeautifulSoup not available")
        
        soup = BeautifulSoup(response.text, 'html.parser')
        events = []
        
        # Parse calendar table (simplified)
        # Note: Actual parsing depends on current HTML structure
        rows = soup.find_all('tr', class_='js-event-item')[:20]
        
        for row in rows:
            try:
                time_el = row.find('td', class_='time')
                currency_el = row.find('td', class_='flagCur')
                event_el = row.find('td', class_='event')
                
                if time_el and event_el:
                    # Get impact (bulls icons)
                    impact_el = row.find('td', class_='sentiment')
                    impact = 'LOW'
                    if impact_el:
                        bulls = len(impact_el.find_all('i', class_='grayFullBullishIcon'))
                        if bulls >= 3:
                            impact = 'HIGH'
                        elif bulls == 2:
                            impact = 'MEDIUM'
                    
                    events.append(NewsEvent(
                        time=time_el.text.strip(),
                        currency=currency_el.text.strip() if currency_el else 'USD',
                        impact=impact,
                        event=event_el.text.strip(),
                        forecast='',
                        previous='',
                        actual='',
                        title_vi=''
                    ))
            except:
                continue
        
        return events
    
    def _get_mock_calendar(self) -> List[NewsEvent]:
        """Mock data khi khÃ´ng crawl Ä‘Æ°á»£c"""
        now = datetime.now()
        
        return [
            NewsEvent(
                time=now.strftime("%H:%M"),
                currency='USD',
                impact='HIGH',
                event='Core CPI m/m',
                forecast='0.3%',
                previous='0.2%',
                actual='',
                title_vi='Chá»‰ sá»‘ CPI lÃµi thÃ¡ng'
            ),
            NewsEvent(
                time=(now + timedelta(hours=2)).strftime("%H:%M"),
                currency='USD',
                impact='HIGH', 
                event='FOMC Statement',
                forecast='',
                previous='',
                actual='',
                title_vi='TuyÃªn bá»‘ cá»§a FOMC'
            )
        ]
    
    def get_high_impact_news(self, currency: str = 'USD') -> List[NewsEvent]:
        """
        Chá»‰ láº¥y tin QUAN TRá»ŒNG (High Impact) cho má»™t loáº¡i tiá»n
        """
        all_events = self.get_economic_calendar()
        
        high_impact = [
            e for e in all_events 
            if e.impact == 'HIGH' and currency.upper() in e.currency.upper()
        ]
        
        # Dá»‹ch sang tiáº¿ng Viá»‡t
        if self.model:
            for event in high_impact:
                event.title_vi = self._translate_event(event.event)
        
        return high_impact
    
    def _translate_event(self, event_name: str) -> str:
        """Dá»‹ch tÃªn sá»± kiá»‡n sang tiáº¿ng Viá»‡t"""
        if not self.model:
            return event_name
        
        # Translation dictionary cho cÃ¡c sá»± kiá»‡n phá»• biáº¿n
        translations = {
            'Non-Farm Payrolls': 'Báº£ng lÆ°Æ¡ng phi nÃ´ng nghiá»‡p',
            'CPI': 'Chá»‰ sá»‘ giÃ¡ tiÃªu dÃ¹ng',
            'Core CPI': 'CPI lÃµi (khÃ´ng thá»±c pháº©m & nÄƒng lÆ°á»£ng)',
            'PPI': 'Chá»‰ sá»‘ giÃ¡ sáº£n xuáº¥t',
            'GDP': 'Tá»•ng sáº£n pháº©m quá»‘c ná»™i',
            'FOMC': 'Cuá»™c há»p á»¦y ban Thá»‹ trÆ°á»ng Má»Ÿ',
            'Interest Rate Decision': 'Quyáº¿t Ä‘á»‹nh lÃ£i suáº¥t',
            'Unemployment Rate': 'Tá»· lá»‡ tháº¥t nghiá»‡p',
            'Retail Sales': 'Doanh sá»‘ bÃ¡n láº»',
            'PMI': 'Chá»‰ sá»‘ quáº£n lÃ½ thu mua',
        }
        
        for eng, vi in translations.items():
            if eng.lower() in event_name.lower():
                return vi
        
        # Use AI for unknown terms
        try:
            prompt = f"Dá»‹ch thuáº­t ngá»¯ tÃ i chÃ­nh sau sang tiáº¿ng Viá»‡t ngáº¯n gá»n (chá»‰ tráº£ vá» báº£n dá»‹ch): {event_name}"
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except:
            return event_name
    
    def should_pause_trading(self, minutes_before: int = 30) -> Tuple[bool, Optional[NewsEvent]]:
        """
        Kiá»ƒm tra cÃ³ nÃªn táº¡m dá»«ng trading khÃ´ng
        (CÃ³ tin High Impact trong X phÃºt tá»›i?)
        
        Returns:
            (should_pause, upcoming_event)
        """
        high_impact = self.get_high_impact_news('USD')
        
        now = datetime.now()
        
        for event in high_impact:
            try:
                # Parse event time
                event_time = datetime.strptime(event.time, "%H:%M").replace(
                    year=now.year, month=now.month, day=now.day
                )
                
                # Check if within window
                time_diff = (event_time - now).total_seconds() / 60
                
                if 0 <= time_diff <= minutes_before:
                    return True, event
            except:
                continue
        
        return False, None
    
    def is_gold_impacting(self, event: NewsEvent) -> bool:
        """Kiá»ƒm tra tin cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n VÃ ng khÃ´ng"""
        for keyword in self.GOLD_IMPACT_EVENTS:
            if keyword.lower() in event.event.lower():
                return True
        return event.currency == 'USD' and event.impact == 'HIGH'
    
    def get_news_summary(self) -> str:
        """Táº¡o tÃ³m táº¯t tin tá»©c"""
        high_impact = self.get_high_impact_news('USD')
        should_pause, upcoming = self.should_pause_trading()
        
        lines = [
            "ğŸ“° TIN Tá»¨C KINH Táº¾",
            "=" * 30,
        ]
        
        if should_pause and upcoming:
            lines.append(f"âš ï¸ Cáº¢NH BÃO: Sáº¯p cÃ³ tin quan trá»ng!")
            lines.append(f"   ğŸ• {upcoming.time} - {upcoming.event}")
            if upcoming.title_vi:
                lines.append(f"   ğŸ‡»ğŸ‡³ {upcoming.title_vi}")
            lines.append(f"   ğŸ’¡ NÃªn Táº M Dá»ªNG giao dá»‹ch Ä‘á»ƒ trÃ¡nh rá»§i ro!")
        else:
            lines.append("âœ… KhÃ´ng cÃ³ tin quan trá»ng sáº¯p tá»›i")
        
        if high_impact:
            lines.append(f"\nğŸ“‹ Tin High Impact hÃ´m nay ({len(high_impact)}):")
            for event in high_impact[:5]:
                icon = "ğŸ”´" if event.impact == 'HIGH' else "ğŸŸ¡"
                lines.append(f"   {icon} {event.time} - {event.event}")
        
        return "\n".join(lines)


# Quick test
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    
    crawler = NewsCrawler(api_key)
    
    print("Testing News Crawler...")
    print(crawler.get_news_summary())
    
    # Test pause check
    should_pause, event = crawler.should_pause_trading()
    print(f"\nShould pause: {should_pause}")
    if event:
        print(f"Upcoming: {event.event}")
